{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "795bd636-7349-421a-b874-f6a5efa33135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import multiprocessing as mp\n",
    "from queue import Empty\n",
    "from queue import Empty\n",
    "from glob import glob\n",
    "import pickle\n",
    "import gzip\n",
    "from typing import Any, Dict, Optional, Tuple\n",
    "from warnings import warn\n",
    "\n",
    "# Third-party library imports\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from pymatgen.io.cif import CifParser\n",
    "from pymatgen.analysis.structure_matcher import StructureMatcher\n",
    "\n",
    "# Conditional imports for backwards compatibility with older pymatgen versions\n",
    "try:\n",
    "    parser_from_string = CifParser.from_str\n",
    "except AttributeError:\n",
    "    parser_from_string = CifParser.from_string\n",
    "\n",
    "from decifer_refactored.decifer_model import Decifer, DeciferConfig\n",
    "from decifer_refactored.decifer_dataset import DeciferDataset\n",
    "from decifer_refactored.tokenizer import Tokenizer\n",
    "from bin_refactored.evaluate import load_model_from_checkpoint, get_cif_statistics, safe_extract, safe_extract_boolean\n",
    "from decifer_refactored.utility import (\n",
    "    get_rmsd,\n",
    "    replace_symmetry_loop_with_P1,\n",
    "    extract_space_group_symbol,\n",
    "    reinstate_symmetry_loop,\n",
    "    is_sensible,\n",
    "    extract_numeric_property,\n",
    "    get_unit_cell_volume,\n",
    "    extract_volume,\n",
    "    is_space_group_consistent,\n",
    "    is_atom_site_multiplicity_consistent,\n",
    "    is_formula_consistent,\n",
    "    bond_length_reasonableness_score,\n",
    "    extract_species,\n",
    "    discrete_to_continuous_xrd,\n",
    "    generate_continuous_xrd_from_cif,\n",
    ")\n",
    "from bin_refactored.train import TrainConfig\n",
    "\n",
    "# Tokenizer, get start, padding and newline IDs\n",
    "TOKENIZER = Tokenizer()\n",
    "VOCAB_SIZE = TOKENIZER.vocab_size\n",
    "START_ID = TOKENIZER.token_to_id[\"data_\"]\n",
    "PADDING_ID = TOKENIZER.padding_id\n",
    "NEWLINE_ID = TOKENIZER.token_to_id[\"\\n\"]\n",
    "SPACEGROUP_ID = TOKENIZER.token_to_id[\"_symmetry_space_group_name_H-M\"]\n",
    "DECODE = TOKENIZER.decode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6cf13cc7-ab27-4640-a713-9b856d696522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99757751baeb4b0c8c363b55c58cf99b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing data: \n",
      "Error processing data: unsupported operand type(s) for +: 'NoneType' and 'FloatWithUnit'\n",
      "Error processing data: unsupported operand type(s) for +: 'NoneType' and 'FloatWithUnit'\n",
      "Error processing data: \n",
      "Error processing data: \n",
      "Error processing data: \n",
      "Error processing data: \n",
      "Error processing data: \n",
      "Error processing data: \n",
      "Error processing data: \n",
      "Error processing data: \n",
      "Error processing data: \n",
      "Error processing data: \n",
      "Error processing data: \n",
      "Error processing data: \n",
      "Error processing data: \n",
      "Error processing data: unsupported operand type(s) for +: 'NoneType' and 'FloatWithUnit'\n",
      "Error processing data: \n",
      "Error processing data: \n",
      "Error processing data: \n",
      "Error processing data: unsupported operand type(s) for +: 'NoneType' and 'FloatWithUnit'\n",
      "Error processing data: unsupported operand type(s) for +: 'NoneType' and 'FloatWithUnit'\n",
      "Error processing data: \n",
      "Error processing data: \n",
      "Error processing data: \n",
      "Error processing data: \n",
      "Error processing data: \n",
      "Error processing data: \n",
      "Error processing data: \n",
      "Error processing data: \n",
      "Summary of Validity Checks:\n",
      "Formulas: 99.18% valid\n",
      "Site Multiplicities: 99.14% valid\n",
      "Bond Lengths: 97.20% valid\n",
      "Spacegroups: 99.18% valid\n",
      "Overall Valid: 97.16%\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Define dataset path and initialize dataset\n",
    "dataset_path = '../data/chili100k/full/serialized/train.h5'\n",
    "dataset = DeciferDataset(dataset_path, [\"cif_name\", \"cif_tokens\", \"xrd.q\", \"xrd.iq\", \"cif_string\", \"spacegroup\"])\n",
    "\n",
    "num_generations = 5000\n",
    "pbar = tqdm(total=num_generations)\n",
    "\n",
    "# Helper function to process a single data point\n",
    "def process_data(data):\n",
    "    cif_string = data['cif_string']\n",
    "\n",
    "    # # Pre-processing\n",
    "    # print(cif_string)\n",
    "    # cif_string = replace_symmetry_loop_with_P1(cif_string)\n",
    "    # spacegroup_symbol = extract_space_group_symbol(cif_string)\n",
    "    # print(spacegroup_symbol)\n",
    "    # if spacegroup_symbol != \"P 1\":\n",
    "    #     cif_string = reinstate_symmetry_loop(cif_string, spacegroup_symbol)\n",
    "    # print(cif_string)\n",
    "\n",
    "    try:\n",
    "        sg = is_space_group_consistent(cif_string)\n",
    "        form = is_formula_consistent(cif_string)\n",
    "        sm = is_atom_site_multiplicity_consistent(cif_string)\n",
    "        bl = bond_length_reasonableness_score(cif_string) >= 1.0\n",
    "        valid = form and sm and bl and sg\n",
    "    except ZeroDivisionError:\n",
    "        form, sm, bl, sg, valid = False, False, False, False, False\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing data: {e}\")\n",
    "        form, sm, bl, sg, valid = False, False, False, False, False\n",
    "\n",
    "    return form, sm, bl, sg, valid\n",
    "\n",
    "# Wrap dataset generation for multiprocessing compatibility\n",
    "def dataset_generator():\n",
    "    for _, data in zip(range(num_generations), dataset):\n",
    "        yield data\n",
    "\n",
    "num_cores = 7\n",
    "with Pool(processes=num_cores) as pool:\n",
    "    results = []\n",
    "    for result in pool.imap_unordered(process_data, dataset_generator(), chunksize=10):\n",
    "        results.append(result)\n",
    "        pbar.update(1)\n",
    "pbar.close()\n",
    "\n",
    "# Unpack results\n",
    "forms, sms, bls, sgs, valids = zip(*results)\n",
    "\n",
    "# Calculate percentages\n",
    "form_percent = (sum(forms) / num_generations) * 100\n",
    "sm_percent = (sum(sms) / num_generations) * 100\n",
    "bl_percent = (sum(bls) / num_generations) * 100\n",
    "sg_percent = (sum(sgs) / num_generations) * 100\n",
    "valid_percent = (sum(valids) / num_generations) * 100\n",
    "\n",
    "# Print summarized results\n",
    "print(\"Summary of Validity Checks:\")\n",
    "print(f\"Formulas: {form_percent:.2f}% valid\")\n",
    "print(f\"Site Multiplicities: {sm_percent:.2f}% valid\")\n",
    "print(f\"Bond Lengths: {bl_percent:.2f}% valid\")\n",
    "print(f\"Spacegroups: {sg_percent:.2f}% valid\")\n",
    "print(f\"Overall Valid: {valid_percent:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c927af4-35d1-470d-8502-f1d26fa3c94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of Validity Checks:\n",
      "Formulas: 2.00% valid\n",
      "Site Multiplicities: 2.00% valid\n",
      "Bond Lengths: 1.80% valid\n",
      "Spacegroups: 2.00% valid\n",
      "Overall Valid: 1.80%\n"
     ]
    }
   ],
   "source": [
    "# Calculate percentages\n",
    "form_percent = (sum(forms) / num_generations) * 100\n",
    "sm_percent = (sum(sms) / num_generations) * 100\n",
    "bl_percent = (sum(bls) / num_generations) * 100\n",
    "sg_percent = (sum(sgs) / num_generations) * 100\n",
    "valid_percent = (sum(valids) / num_generations) * 100\n",
    "\n",
    "# Print summarized results\n",
    "print(\"Summary of Validity Checks:\")\n",
    "print(f\"Formulas: {form_percent:.2f}% valid\")\n",
    "print(f\"Site Multiplicities: {sm_percent:.2f}% valid\")\n",
    "print(f\"Bond Lengths: {bl_percent:.2f}% valid\")\n",
    "print(f\"Spacegroups: {sg_percent:.2f}% valid\")\n",
    "print(f\"Overall Valid: {valid_percent:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0980e59c-6474-405d-ba56-55f59945508e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
