{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b82443e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\n",
       "\\begin{aligned}\n",
       "& \\text{Table: Validity Metrics Comparison between Datasets (Percentage of Valid Entries)}\\\\\n",
       "&\\begin{array}{|c|c|c|c|c|}\n",
       "\\hline\n",
       "\\text{Dataset} & \\text{Formula Validity (%)} & \\text{Spacegroup Validity (%)} & \\text{Bond Length Validity (%)} & \\text{Site Multiplicity Validity (%)} \\\\\n",
       "\\hline\n",
       "\\text{boundary_masking_100} & 97.00 & 95.00 & 70.00 & 93.00 \\\\\n",
       "\\hline\n",
       "\\text{no_boundary_masking_100} & 95.00 & 94.00 & 73.00 & 89.00 \\\\\n",
       "\\hline\n",
       "\\text{crystal_train_1000} & 100.00 & 98.10 & 95.90 & 100.00 \\\\\n",
       "\\hline\n",
       "\\end{array}\\end{aligned}"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from IPython.display import display, Latex\n",
    "\n",
    "def extract_validity_stats(df):\n",
    "    \"\"\"\n",
    "    Extract validity statistics from the dataset.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing validity columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with validity statistics.\n",
    "    \"\"\"\n",
    "    validity_columns = ['validity.formula', 'validity.spacegroup', 'validity.bond_length', 'validity.site_multiplicity']\n",
    "    \n",
    "    # Ensure the columns are treated as boolean\n",
    "    df[validity_columns] = df[validity_columns].astype(bool)\n",
    "    \n",
    "    # Calculate the percentage of valid entries for each metric\n",
    "    validity_stats = df[validity_columns].mean() * 100\n",
    "    \n",
    "    return validity_stats\n",
    "\n",
    "def dataset_validity_table(eval_paths):\n",
    "    \"\"\"\n",
    "    Extract validity statistics from multiple datasets and prepare a comparison table.\n",
    "\n",
    "    Parameters:\n",
    "        eval_paths (list): List of paths to evaluation files.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the validity statistics comparison table.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    # Process each dataset\n",
    "    for path in eval_paths:\n",
    "        dataset_name = os.path.basename(path).split('.')[0]\n",
    "        \n",
    "        # Load dataset and calculate validity stats\n",
    "        df = pd.read_parquet(path)\n",
    "        validity_stats = extract_validity_stats(df)\n",
    "        \n",
    "        # Add the dataset name to the stats\n",
    "        validity_stats['Dataset'] = dataset_name\n",
    "        results.append(validity_stats)\n",
    "\n",
    "    # Combine all results into a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df[['Dataset', 'validity.formula', 'validity.spacegroup', 'validity.bond_length', 'validity.site_multiplicity']]\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "def display_latex_table(results_df):\n",
    "    \"\"\"\n",
    "    Display the validity statistics as a LaTeX table.\n",
    "\n",
    "    Parameters:\n",
    "        results_df (pd.DataFrame): DataFrame containing the validity statistics.\n",
    "    \"\"\"\n",
    "    # Create LaTeX-like string to display\n",
    "    table_str = r\"\"\"\n",
    "\\begin{aligned}\n",
    "& \\text{Table: Validity Metrics Comparison between Datasets (Percentage of Valid Entries)}\\\\\n",
    "&\\begin{array}{|c|c|c|c|c|}\n",
    "\\hline\n",
    "\\text{Dataset} & \\text{Formula Validity (%)} & \\text{Spacegroup Validity (%)} & \\text{Bond Length Validity (%)} & \\text{Site Multiplicity Validity (%)} \\\\\n",
    "\\hline\n",
    "\"\"\"\n",
    "\n",
    "    # Add rows from DataFrame to the LaTeX string\n",
    "    for _, row in results_df.iterrows():\n",
    "        table_str += f\"\\\\text{{{row['Dataset']}}} & {row['validity.formula']:.2f} & {row['validity.spacegroup']:.2f} & {row['validity.bond_length']:.2f} & {row['validity.site_multiplicity']:.2f} \\\\\\\\\\n\"\n",
    "        table_str += r\"\\hline\" + \"\\n\"\n",
    "\n",
    "    # Close the table\n",
    "    table_str += r\"\\end{array}\\end{aligned}\"\n",
    "\n",
    "    # Display the LaTeX-like table\n",
    "    display(Latex(table_str))\n",
    "\n",
    "# Example usage (update with your eval file paths)\n",
    "eval_paths = [\n",
    "    '../cross-contamination/deciferdataset_experiment/boundarymasking/boundary_masking_100.eval',\n",
    "    '../cross-contamination/deciferdataset_experiment/no_boundarymasking/no_boundary_masking_100.eval',\n",
    "    '../nomodel/crystal_1k/nmax8_lmax5/crystal_train_1000.eval'\n",
    "]\n",
    "\n",
    "# Generate the validity comparison table\n",
    "results_df = dataset_validity_table(eval_paths)\n",
    "\n",
    "# Display the LaTeX table\n",
    "display_latex_table(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
