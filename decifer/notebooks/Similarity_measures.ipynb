{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2569d26b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllrrr}\n",
      "\\toprule\n",
      " & Dataset 1 & Dataset 2 & MMD & Wasserstein Distance & Proxy-A-Distance \\\\\n",
      "\\midrule\n",
      "0 & crystal_train_1000 & boundary_masking_100 & 0.011466 & 633.618072 & 1.631831 \\\\\n",
      "1 & crystal_train_1000 & no_boundary_masking_100 & 0.011954 & 583.466831 & 1.697086 \\\\\n",
      "2 & boundary_masking_100 & no_boundary_masking_100 & 0.021374 & 127.511372 & 0.447503 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\n",
       "\\begin{aligned}\n",
       "& \\text{Table: MMD, Wasserstein, and Proxy-A-Distance between datasets}\\\\\n",
       "&\\begin{array}{|c|c|c|c|c|}\n",
       "\\hline\n",
       "\\text{Dataset 1} & \\text{Dataset 2} & \\text{MMD}\\;\\downarrow & \\text{WD}\\;\\downarrow & \\text{PAD-RF}\\;\\uparrow \\\\\n",
       "\\hline\n",
       "\\text{crystal_train_1000} & \\text{boundary_masking_100} & 0.011 & 633.62 & 1.63 \\\\\n",
       "\\hline\n",
       "\\text{crystal_train_1000} & \\text{no_boundary_masking_100} & 0.012 & 583.47 & 1.70 \\\\\n",
       "\\hline\n",
       "\\text{boundary_masking_100} & \\text{no_boundary_masking_100} & 0.021 & 127.51 & 0.45 \\\\\n",
       "\\hline\n",
       "\\end{array}\\end{aligned}"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import pandas as pd\n",
    "import os\n",
    "import ot\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from IPython.display import display, Math\n",
    "\n",
    "def rbf_kernel(X, Y=None, gamma=1.0):\n",
    "    \"\"\"Compute the RBF (Gaussian) kernel between X and Y.\"\"\"\n",
    "    if Y is None:\n",
    "        Y = X\n",
    "    dist = np.sum(X**2, axis=1)[:, np.newaxis] + np.sum(Y**2, axis=1)[np.newaxis, :] - 2 * np.dot(X, Y.T)\n",
    "    return np.exp(-gamma * dist)\n",
    "\n",
    "def compute_mmd(X, Y, gamma=1.0):\n",
    "    \"\"\"Compute Maximum Mean Discrepancy (MMD) between two sets of samples.\"\"\"\n",
    "    K_XX = rbf_kernel(X, X, gamma=gamma)\n",
    "    K_YY = rbf_kernel(Y, Y, gamma=gamma)\n",
    "    K_XY = rbf_kernel(X, Y, gamma=gamma)\n",
    "    mmd = np.mean(K_XX) + np.mean(K_YY) - 2 * np.mean(K_XY)\n",
    "    return mmd\n",
    "\n",
    "def compute_wasserstein_nd(X, Y):\n",
    "    \"\"\"Compute the Wasserstein distance between two multi-dimensional distributions.\"\"\"\n",
    "    M = ot.dist(X, Y, metric='euclidean')\n",
    "    n = X.shape[0]\n",
    "    m = Y.shape[0]\n",
    "    p = np.ones(n) / n  # Uniform distribution for X\n",
    "    q = np.ones(m) / m  # Uniform distribution for Y\n",
    "    dist = ot.emd2(p, q, M)\n",
    "    return dist\n",
    "\n",
    "def compute_proxy_a_distance(X, Y):\n",
    "    \"\"\"Compute Proxy-A-Distance (PAD) between two distributions using a Random Forest classifier.\"\"\"\n",
    "    # Combine datasets\n",
    "    X_combined = np.vstack([X, Y])\n",
    "    y_combined = np.hstack([np.zeros(X.shape[0]), np.ones(Y.shape[0])])  # 0 for X, 1 for Y\n",
    "    \n",
    "    # Train a Random Forest classifier and compute cross-validated accuracy\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    error_rates = 1 - cross_val_score(clf, X_combined, y_combined, cv=5, scoring='accuracy')\n",
    "    avg_error_rate = np.mean(error_rates)\n",
    "    \n",
    "    # Compute PAD based on classification error rate\n",
    "    pad_value = 2 * (1 - 2 * avg_error_rate)\n",
    "    return pad_value\n",
    "\n",
    "def dataset_feature_vectors(eval_path, columns_to_concat):\n",
    "    df = pd.read_parquet(eval_path)\n",
    "#     print(df)\n",
    "    df = df.dropna(subset=columns_to_concat)\n",
    "    return np.vstack(df[columns_to_concat].apply(lambda row: np.array(row.values.tolist()), axis=1))\n",
    "\n",
    "# Configuration\n",
    "columns_to_concat = [\n",
    "    'cell_params.a', \n",
    "    'cell_params.b',\n",
    "    'cell_params.c',\n",
    "    'cell_params.alpha', \n",
    "    'cell_params.beta', \n",
    "    'cell_params.gamma', \n",
    "    'cell_params.implied_vol',\n",
    "    'cell_params.gen_vol',\n",
    "    'seq_len',\n",
    "]\n",
    "eval_paths = [\n",
    "    '../nomodel/crystal_1k/nmax8_lmax5/crystal_train_1000.eval',\n",
    "    '../cross-contamination/deciferdataset_experiment/boundarymasking/boundary_masking_100.eval',\n",
    "    '../cross-contamination/deciferdataset_experiment/no_boundarymasking/no_boundary_masking_100.eval',\n",
    "]\n",
    "eval_names = [os.path.basename(path) for path in eval_paths]\n",
    "\n",
    "# Extract feature vectors\n",
    "feature_vectors = []\n",
    "for path in eval_paths:\n",
    "    vec = dataset_feature_vectors(path, columns_to_concat)\n",
    "    feature_vectors.append(vec)\n",
    "\n",
    "# Initialize results table\n",
    "results = []\n",
    "\n",
    "# Compute pairwise MMD, Wasserstein, and PAD\n",
    "for i in range(len(eval_names)):\n",
    "    for j in range(i + 1, len(eval_names)):\n",
    "        mmd_value = compute_mmd(feature_vectors[i], feature_vectors[j], gamma=1.0)\n",
    "        dist_nd = compute_wasserstein_nd(feature_vectors[i], feature_vectors[j])\n",
    "        pad_value = compute_proxy_a_distance(feature_vectors[i], feature_vectors[j])\n",
    "        \n",
    "        # Store results in a list\n",
    "        results.append({\n",
    "            \"Dataset 1\": eval_names[i].split(\".\")[0],\n",
    "            \"Dataset 2\": eval_names[j].split(\".\")[0],\n",
    "            \"MMD\": mmd_value,\n",
    "            \"Wasserstein Distance\": dist_nd,\n",
    "            \"Proxy-A-Distance\": pad_value\n",
    "        })\n",
    "\n",
    "# Convert results to a DataFrame and display the table\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(results_df.to_latex())\n",
    "\n",
    "from IPython.display import display, Latex\n",
    "\n",
    "# Create LaTeX-like string to display\n",
    "table_str = r\"\"\"\n",
    "\\begin{aligned}\n",
    "& \\text{Table: MMD, Wasserstein, and Proxy-A-Distance between datasets}\\\\\n",
    "&\\begin{array}{|c|c|c|c|c|}\n",
    "\\hline\n",
    "\\text{Dataset 1} & \\text{Dataset 2} & \\text{MMD}\\;\\downarrow & \\text{WD}\\;\\downarrow & \\text{PAD-RF}\\;\\uparrow \\\\\n",
    "\\hline\n",
    "\"\"\"\n",
    "\n",
    "# Add rows from DataFrame to the LaTeX string\n",
    "for _, row in results_df.iterrows():\n",
    "    table_str += f\"\\\\text{{{row['Dataset 1']}}} & \\\\text{{{row['Dataset 2']}}} & {row['MMD']:.3f} & {row['Wasserstein Distance']:.2f} & {row['Proxy-A-Distance']:.2f} \\\\\\\\\\n\"\n",
    "    table_str += r\"\\hline\" + \"\\n\"\n",
    "\n",
    "# Close the table\n",
    "table_str += r\"\\end{array}\\end{aligned}\"\n",
    "\n",
    "# Display the LaTeX-like table\n",
    "display(Latex(table_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dcb681e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is pdfTeX, Version 3.14159265-2.6-1.40.20 (TeX Live 2019/Debian) (preloaded format=latex)\n",
      " restricted \\write18 enabled.\n",
      "entering extended mode\n",
      "(./latex_input.tex\n",
      "LaTeX2e <2020-02-02> patch level 2\n",
      "L3 programming layer <2020-02-14>\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/standalone/standalone.cls\n",
      "Document Class: standalone 2018/03/26 v1.3a Class to compile TeX sub-files stan\n",
      "dalone\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/tools/shellesc.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/iftex/ifluatex.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/iftex/iftex.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/xkeyval/xkeyval.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/xkeyval/xkeyval.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/xkeyval/xkvutils.tex\n",
      "(/usr/share/texlive/texmf-dist/tex/generic/xkeyval/keyval.tex))))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/standalone/standalone.cfg)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/base/article.cls\n",
      "Document Class: article 2019/12/20 v1.4l Standard LaTeX document class\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/base/size10.clo)))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsmath/amsmath.sty\n",
      "For additional information on amsmath, use the `?' option.\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsmath/amstext.sty\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsmath/amsgen.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsmath/amsbsy.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/amsmath/amsopn.sty))\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/booktabs/booktabs.sty)\n",
      "(/usr/share/texlive/texmf-dist/tex/latex/l3backend/l3backend-dvips.def)\n",
      "No file latex_input.aux.\n",
      "[1] (./latex_input.aux) )\n",
      "Output written on latex_input.dvi (1 page, 616 bytes).\n",
      "Transcript written on latex_input.log.\n",
      "This is dvipng 1.15 Copyright 2002-2015 Jan-Ake Larsson\n",
      "[1 <raw PostScript>] \n",
      "PNG image successfully created: table_example.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dvipng warning: No image output from inclusion of raw PostScript "
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "def latex_to_png(latex_code, output_filename='output.png', dpi=300):\n",
    "    # Step 1: Write LaTeX code to a .tex file\n",
    "    tex_filename = 'latex_input.tex'\n",
    "    with open(tex_filename, 'w') as f:\n",
    "        # Ensure content is wrapped properly in a full LaTeX document\n",
    "        f.write(r\"\"\"\n",
    "        \\documentclass{standalone}\n",
    "        \\usepackage{amsmath, booktabs} % Add more packages if necessary\n",
    "        \\begin{document}\n",
    "        \"\"\" + latex_code + r\"\"\"\n",
    "        \\end{document}\n",
    "        \"\"\")\n",
    "\n",
    "    try:\n",
    "        # Step 2: Compile the .tex file to a DVI file using `latex`\n",
    "        subprocess.run(['latex', tex_filename], check=True)\n",
    "\n",
    "        # Step 3: Convert the .dvi file to PNG using `dvipng`\n",
    "        dvi_filename = tex_filename.replace('.tex', '.dvi')\n",
    "        subprocess.run(['dvipng', '-D', str(dpi), '-T', 'tight', '-o', output_filename, dvi_filename], check=True)\n",
    "\n",
    "        print(f\"PNG image successfully created: {output_filename}\")\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        # Optional: Clean up the intermediate files (DVI, AUX, LOG)\n",
    "        for ext in ['aux', 'log', 'dvi', 'tex']:\n",
    "            if os.path.exists(f'latex_input.{ext}'):\n",
    "                os.remove(f'latex_input.{ext}')\n",
    "\n",
    "# Example usage with a table or other complex LaTeX content\n",
    "latex_code = r\"\"\"\n",
    "\\begin{tabular}{lccc}\n",
    "    \\toprule\n",
    "    & \\textbf{Metric 1} & \\textbf{Metric 2} & \\textbf{Metric 3} \\\\\n",
    "    \\midrule\n",
    "    \\text{Dataset 1} & 0.123 & 0.456 & 0.789 \\\\\n",
    "    \\text{Dataset 2} & 0.987 & 0.654 & 0.321 \\\\\n",
    "    \\bottomrule\n",
    "\\end{tabular}\n",
    "\"\"\"\n",
    "\n",
    "latex_to_png(latex_code, output_filename='table_example.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
