{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2559b1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from decifer import (\n",
    "    HDF5Dataset,\n",
    ")\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, vocab_size, token_input_size, numeric_input_size, hidden_size, output_size):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        \n",
    "        # Tokenized data goes through embedding and a simple feedforward layer\n",
    "        self.embedding = nn.Embedding(vocab_size, token_input_size)  # Adjust vocabulary size\n",
    "        self.fc_token = nn.Linear(token_input_size, hidden_size)\n",
    "\n",
    "        # Numeric data goes through a simple linear layer\n",
    "        self.fc_numeric = nn.Linear(numeric_input_size, hidden_size)  # Make sure numeric_input_size matches the actual numeric data dimension\n",
    "\n",
    "        # Final layer to produce the output\n",
    "        self.fc_out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, token_data, numeric_data):\n",
    "        # Tokenized data\n",
    "        embedded = self.embedding(token_data)\n",
    "        token_output = self.fc_token(embedded.mean(dim=1))  # Take mean across tokens\n",
    "\n",
    "        # Numeric data\n",
    "        numeric_output = self.fc_numeric(numeric_data)\n",
    "\n",
    "        # Combine both outputs\n",
    "        combined_output = token_output + numeric_output\n",
    "\n",
    "        # Final output\n",
    "        return self.fc_out(combined_output)\n",
    "\n",
    "\n",
    "# Function to train the model\n",
    "def train_model(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        # Send data to device (GPU or CPU)\n",
    "        token_data, numeric_data = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(token_data, numeric_data)\n",
    "        loss = criterion(outputs, numeric_data)  # Using numeric data as the target for simplicity\n",
    "        print(loss)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    return running_loss / len(train_loader)\n",
    "\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            token_data, numeric_data = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "            outputs = model(token_data, numeric_data)\n",
    "            loss = criterion(outputs, numeric_data)  # Using numeric data as the target for simplicity\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    return running_loss / len(val_loader)\n",
    "\n",
    "\n",
    "# Simple training loop\n",
    "def run_training(train_loader, val_loader, vocab_size, token_input_size, numeric_input_size, hidden_size, output_size, epochs=5):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Initialize model, loss function, and optimizer\n",
    "    model = SimpleModel(vocab_size, token_input_size, numeric_input_size, hidden_size, output_size).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_model(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss = evaluate_model(model, val_loader, criterion, device)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41685a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2649, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2322, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2175, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2119, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1963, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1981, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2057, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2047, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1956, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1866, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1962, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1953, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1853, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1877, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1929, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1848, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1892, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1860, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1869, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1854, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1834, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1826, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1828, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1793, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1775, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1783, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1751, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1746, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1756, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1760, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1789, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1709, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1736, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1706, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1729, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1668, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1677, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1684, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1697, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1670, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1671, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1666, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1662, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1628, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1654, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1647, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1627, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1575, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1578, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1634, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1565, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1537, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1594, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1545, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1559, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1567, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1577, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1601, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1495, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1555, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1507, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1477, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1471, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1509, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1474, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1467, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1516, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1463, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1459, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1440, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1444, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1428, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1425, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1488, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1416, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1410, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1388, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1423, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1391, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1400, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1408, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1373, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1378, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1397, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1359, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1364, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1347, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1365, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1390, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1355, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1318, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1329, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1375, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1300, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1295, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1302, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1303, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1289, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1268, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1275, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1282, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1311, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1277, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1273, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1270, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1273, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1285, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1231, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1221, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1222, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1232, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1227, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1220, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1211, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1236, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1186, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1203, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1202, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1210, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1160, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1169, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1193, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1177, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1186, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1159, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1141, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1162, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1146, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1102, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1143, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1132, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1091, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1089, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1097, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1107, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1102, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1102, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1068, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1077, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1084, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1068, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1057, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1061, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1047, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1026, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1043, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1038, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1026, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1046, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0970, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0997, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0984, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0960, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0968, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0986, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0969, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0963, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0947, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0941, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0918, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0922, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0952, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0929, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0928, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0901, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0916, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0904, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0915, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0872, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0908, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0892, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0904, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0856, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0851, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0876, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0840, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0845, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0846, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0828, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0855, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0859, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0837, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0826, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0841, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0827, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0798, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0807, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0790, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0791, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0780, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0824, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0784, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0782, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0780, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0790, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0761, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0762, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0774, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0776, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0762, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0762, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0729, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0740, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0703, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0731, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0700, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0703, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0721, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0710, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0706, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0709, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0677, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0673, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0679, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0677, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0688, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0668, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0679, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0711, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0647, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0678, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0666, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0661, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0647, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0643, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0661, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0665, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0631, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0649, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0613, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0639, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0608, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0608, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0622, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0611, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0580, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0585, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0599, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0619, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0584, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0609, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0577, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0564, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0560, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0554, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0583, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0558, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0558, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0565, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0540, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0552, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0544, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0539, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0524, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0540, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0540, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0526, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0536, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0517, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0514, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0507, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0508, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0507, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0514, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0486, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0524, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0480, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0474, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0486, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0478, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0488, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0500, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0489, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0453, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0480, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0461, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0439, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0446, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0465, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0460, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0448, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0446, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0451, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0450, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0411, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0422, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0430, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0434, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0429, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0414, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0427, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0430, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0427, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0405, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0409, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0390, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0397, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0380, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0402, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0398, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0393, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0390, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0371, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0377, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0372, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0378, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0355, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0385, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0365, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0351, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0350, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0346, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0370, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0344, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0354, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0351, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0337, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0357, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0361, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0322, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0339, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0352, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0339, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0343, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0334, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0318, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0324, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0320, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0315, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0337, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0305, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0315, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0326, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0308, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0312, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0309, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0313, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0303, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0310, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0307, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0303, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0290, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0321, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0304, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0290, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0283, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0290, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0290, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0285, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0289, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0292, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0290, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0281, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0278, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0278, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0283, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0284, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0283, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0275, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0273, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0267, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0264, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0276, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0261, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0278, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0271, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0277, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0261, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0251, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0252, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0260, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0254, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0243, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0234, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0247, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0250, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0244, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0248, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0266, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0237, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0236, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0232, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0216, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0238, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0228, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0257, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0241, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0233, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0223, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0231, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0246, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0226, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0213, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0218, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0212, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0221, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0206, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0225, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0224, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0217, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0214, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0215, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0205, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0204, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0202, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0198, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0192, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0207, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0208, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0194, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0209, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0197, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0188, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0201, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0219, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0196, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0191, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0195, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0193, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0184, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0172, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0189, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0178, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0185, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0174, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0187, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0177, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0183, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0171, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0176, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0152, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0170, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0181, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0154, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0173, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0167, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0169, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m output_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m  \u001b[38;5;66;03m# Output size (same as input size for simplicity)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m vocab_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m372\u001b[39m\n\u001b[0;32m---> 18\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_input_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_input_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Evaluate on test set (for simplicity)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m evaluate_model(trained_model, test_loader, nn\u001b[38;5;241m.\u001b[39mMSELoss(), torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "Cell \u001b[0;32mIn[6], line 89\u001b[0m, in \u001b[0;36mrun_training\u001b[0;34m(train_loader, val_loader, vocab_size, token_input_size, numeric_input_size, hidden_size, output_size, epochs)\u001b[0m\n\u001b[1;32m     86\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 89\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m evaluate_model(model, val_loader, criterion, device)\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Val Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 42\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     40\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     41\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# Send data to device (GPU or CPU)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     token_data, numeric_data \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), batch[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# Zero the parameter gradients\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/decifer_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/decifer_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/decifer_env/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/decifer_env/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/phd_projects/deCIFer/decifer/scripts/dataset.py:27\u001b[0m, in \u001b[0;36mHDF5Dataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m---> 27\u001b[0m     sequence_chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_sequence_and_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     29\u001b[0m     block_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock_size  \u001b[38;5;66;03m# Cache the block size for faster access\u001b[39;00m\n",
      "File \u001b[0;32m~/phd_projects/deCIFer/decifer/scripts/dataset.py:64\u001b[0m, in \u001b[0;36mHDF5Dataset.find_sequence_and_chunk\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     62\u001b[0m total_chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_to_load:\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, sequence \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[key]):\n\u001b[1;32m     65\u001b[0m         num_chunks \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(sequence) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock_size \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock_size\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m<\u001b[39m total_chunks \u001b[38;5;241m+\u001b[39m num_chunks:\n",
      "File \u001b[0;32m~/miniconda3/envs/decifer_env/lib/python3.9/site-packages/h5py/_hl/dataset.py:715\u001b[0m, in \u001b[0;36mDataset.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt iterate over a scalar dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(shape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m--> 715\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/decifer_env/lib/python3.9/site-packages/h5py/_hl/dataset.py:841\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, args, new_dtype)\u001b[0m\n\u001b[1;32m    839\u001b[0m mspace \u001b[38;5;241m=\u001b[39m h5s\u001b[38;5;241m.\u001b[39mcreate_simple(selection\u001b[38;5;241m.\u001b[39mmshape)\n\u001b[1;32m    840\u001b[0m fspace \u001b[38;5;241m=\u001b[39m selection\u001b[38;5;241m.\u001b[39mid\n\u001b[0;32m--> 841\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdxpl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dxpl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;66;03m# Patch up the output for NumPy\u001b[39;00m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m ():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Example dataset loading (adjust paths as necessary)\n",
    "block_size = 12\n",
    "train_dataset = HDF5Dataset('../data/chili100k/hdf5_data/train_dataset.h5', ['cif_tokenized', 'xrd_cont_y'], block_size)\n",
    "val_dataset = HDF5Dataset('../data/chili100k/hdf5_data/val_dataset.h5', ['cif_tokenized', 'xrd_cont_y'], block_size)\n",
    "test_dataset = HDF5Dataset('../data/chili100k/hdf5_data/test_dataset.h5', ['cif_tokenized', 'xrd_cont_y'], block_size)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Run training\n",
    "token_input_size = 2  # Embedding size for tokenized input\n",
    "numeric_input_size = 1000  # Size of numeric input\n",
    "hidden_size = 2  # Size of hidden layers\n",
    "output_size = 1000  # Output size (same as input size for simplicity)\n",
    "vocab_size = 372\n",
    "\n",
    "trained_model = run_training(train_loader, val_loader, vocab_size, token_input_size, numeric_input_size, hidden_size, output_size, epochs=5)\n",
    "\n",
    "# Evaluate on test set (for simplicity)\n",
    "test_loss = evaluate_model(trained_model, test_loader, nn.MSELoss(), torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f733eed2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
